# scratch-nn

A minimal neural network implemented from scratch in NumPy, designed for educational purposes and foundational understanding of deep learning principles.

## Features

- Fully-connected (feedforward) neural network  
- Softmax activation in the output layer  
- Cross-entropy loss function  
- L2 regularization  
- Custom training loop with mini-batch SGD

## Limitations

- No support for ReLU or other non-sigmoid activations  
- No momentum or adaptive optimizers  
- No support for convolutional or recurrent architectures
